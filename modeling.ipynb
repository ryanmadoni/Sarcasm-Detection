{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9thyws0YVeJ"
      },
      "source": [
        "#### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SVeKFOXUaSlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "262Td2bPGm8L"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn\n",
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssr8F1pnYVeU"
      },
      "source": [
        "#### Load Necesary Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwAkTJcAJnkG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from transformers import (BertTokenizerFast,\n",
        "                          BertForSequenceClassification,\n",
        "                          DistilBertTokenizerFast,\n",
        "                          DistilBertForSequenceClassification,\n",
        "                          Trainer, TrainingArguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhHmNjZFYVeV"
      },
      "source": [
        "#### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDRivaE1KYWA"
      },
      "outputs": [],
      "source": [
        "# Model Parameters.\n",
        "\n",
        "# \"bert-base-uncased\"\n",
        "# \"distilbert-base-uncased\"\n",
        "\n",
        "modelName = \"distilbert-base-cased\"  # Other models: https://huggingface.co/models.\n",
        "tokenizerType = DistilBertTokenizerFast  # Set the tokenizer type for the model.\n",
        "taskType = DistilBertForSequenceClassification  # Set the correct task type.\n",
        "targets = ['0', '1']  # '0' for not sarcastic.  '1' for sarcastic.\n",
        "\n",
        "# Dataset Parameters.\n",
        "trainFileName = \"/content/drive/MyDrive/data/training_unclean.json\"  # Location for training set.\n",
        "validFileName = \"/content/drive/MyDrive/data/validation_unclean.json\"  # Location for validation set.\n",
        "testFileName = \"/content/drive/MyDrive/data/testing_unclean.json\"  # Location for testing set.\n",
        "maxLength = 64  # Max length for each comment.\n",
        "trainSampling, validSampling, testSampling = 10000, 5000, 2500  # Sampling sizes.\n",
        "sampling = False  # A boolean denoting whether to sample the dataset.\n",
        "useParentComments = True  # A boolean denoting whether to use parent comments.\n",
        "\n",
        "# Training Parameters.\n",
        "outputDirectory = \"/content/drive/MyDrive/models/Bert Unclean Parent 64/results\"  # The location of the results of training.\n",
        "loggingDirectory = \"/content/drive/MyDrive/models/Bert Unclean Parent 64/logs\"  # The location of the logs.\n",
        "epochs = 4  # The number of epochs to train on.\n",
        "trainBatch = 16  # The size of a training batch.\n",
        "evalBatch = 20  # The size of a validation batch.\n",
        "warmupSteps = 500  # The number of warm-up steps.\n",
        "weightDecay = 0.01  # The value of the weight decay.\n",
        "loggingSteps = 20000  # The number of logging steps.\n",
        "saveSteps = 20000  # The number of save steps.\n",
        "loadBestModel = True  # Denoting whether we load the best model after training.\n",
        "evaluationStrategy = \"steps\"  # The evaluation strategy for the trainer.\n",
        "\n",
        "# Saving Model Parameters.\n",
        "modelDirectory = \"/content/drive/MyDrive/models/Bert Unclean Parent 64/sarcasm\"  # Where to save the model after training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEAJQXPrYVeW"
      },
      "source": [
        "#### Load The Data Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HtdMbMpuU9Y"
      },
      "outputs": [],
      "source": [
        "def parseDataset(fileName):\n",
        "    \"\"\"\n",
        "    Takes as input a fileName of a json file, then opens the\n",
        "    file and returns three lists for the parent and child comments\n",
        "    and labels for sarcastic or not sarcastic.\n",
        "    \"\"\"\n",
        "    parentText, childText, labels = [], [], []  # Instantiate containers.\n",
        "\n",
        "    # Open the training data and convert it to a json list.\n",
        "    with open(fileName, 'r') as json_file:\n",
        "        jsonl = list(json_file)\n",
        "\n",
        "    # Loop through all elements in the json list.\n",
        "    for dataEntry in jsonl:\n",
        "        data = json.loads(dataEntry)  # Load the dictionary.\n",
        "\n",
        "        # Construct the parent, child, and label\n",
        "        # lists that will be returned.\n",
        "        parentText.append(data[\"parent\"])\n",
        "        childText.append(data[\"child\"])\n",
        "        labels.append(int(data[\"label\"][0]))\n",
        "\n",
        "    # Return the data with the parent comment\n",
        "    # if the flag is set to True.\n",
        "    if useParentComments:\n",
        "        return labels, parentText, childText\n",
        "\n",
        "    return labels, childText  # Return the data without the parent comment.\n",
        "\n",
        "\n",
        "# Initialize training, validation, and testing sets.\n",
        "trainData = parseDataset(trainFileName)\n",
        "validData = parseDataset(validFileName)\n",
        "testData = parseDataset(testFileName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ7cEUogZMu5"
      },
      "source": [
        "#### Sample the Data for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB1rYuvEYVeY"
      },
      "outputs": [],
      "source": [
        "# Check if sampling is set to True.\n",
        "if sampling:\n",
        "\n",
        "    # Sample training data, validation, and testing data.\n",
        "    trainData = [field[:trainSampling] for field in trainData]\n",
        "    validData = [field[:validSampling] for field in validData]\n",
        "    testData = [field[:testSampling] for field in testData]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhGbxyAAbKMd"
      },
      "source": [
        "#### Tokenize the Data Sets and Convert to a PyTorch Friendly Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7riiOpJiXdTd"
      },
      "outputs": [],
      "source": [
        "# Instantiate the tokenizer for the model.\n",
        "tokenizer = tokenizerType.from_pretrained(modelName, do_lower_case=True)\n",
        "\n",
        "class SarcasmDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    A class to tokenize and convert the datasets\n",
        "    above to PyTorch friendly formats.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        \"\"\"The init function used to initialize the encodings and labels.\"\"\"\n",
        "        self.encodings, self.labels = self.encode(dataset[1:]), dataset[0]\n",
        "\n",
        "    def encode(self, dataset):\n",
        "        \"\"\"Takes as input the dataset and encodes the comments.\"\"\"\n",
        "\n",
        "        # Tokenize the dataset, truncate or pad to the maxLength,\n",
        "        # then return the tokenized data of the comments.\n",
        "        return tokenizer(*dataset, truncation=True,\n",
        "                         padding=True, max_length=maxLength)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Takes as input an id and returns that item.\n",
        "        \"\"\"\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item  # Return the item.\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the length of the labels.\"\"\"\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "# Tokenize and convert the datsets into torch Datasets.\n",
        "trainData = SarcasmDataset(trainData)\n",
        "validData = SarcasmDataset(validData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5qFLILXbW_B"
      },
      "source": [
        "#### Load the Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4aAwDGZXnyk"
      },
      "outputs": [],
      "source": [
        "# Load the model using the model specified above and pass the value to CUDA.\n",
        "model = taskType.from_pretrained(modelName, num_labels=len(targets)).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w30lkC6QxSfJ"
      },
      "source": [
        "#### Construct the Trainer to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjMB9f01Pyiu"
      },
      "outputs": [],
      "source": [
        "def computeMetrics(prediction):\n",
        "    \"\"\"\n",
        "    Takes in a prediction and computes the accuracy\n",
        "    using the \"accuracy_score\" function from sklearn.\n",
        "    \"\"\"\n",
        "    predictions = prediction.predictions.argmax(-1)\n",
        "    return {'accuracy': accuracy_score(prediction.label_ids, predictions)}\n",
        "\n",
        "\n",
        "# Initialize the training arguments.\n",
        "trainingArguments = TrainingArguments(output_dir=outputDirectory,\n",
        "                                      num_train_epochs=epochs,\n",
        "                                      per_device_train_batch_size=trainBatch,\n",
        "                                      per_device_eval_batch_size=evalBatch,\n",
        "                                      warmup_steps=warmupSteps,\n",
        "                                      weight_decay=weightDecay,\n",
        "                                      logging_dir=loggingDirectory,\n",
        "                                      load_best_model_at_end=loadBestModel,\n",
        "                                      logging_steps=loggingSteps,\n",
        "                                      save_steps=saveSteps,\n",
        "                                      evaluation_strategy=evaluationStrategy)\n",
        "\n",
        "# Initialize the trainer.\n",
        "trainer = Trainer(model=model, args=trainingArguments, train_dataset=trainData,\n",
        "                  eval_dataset=validData, compute_metrics=computeMetrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4FF4z3cbi8C"
      },
      "source": [
        "#### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5a7QY_wP5iD"
      },
      "outputs": [],
      "source": [
        "trainer.train()  # Train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri8p9la405sa"
      },
      "source": [
        "#### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdWlnZxAR0XA"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()  # Evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL5R3SFi2LgS"
      },
      "source": [
        "#### Save the Model & Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojgBg7cfSp4J"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(modelDirectory)  # Save the fine-tuned model.\n",
        "tokenizer.save_pretrained(modelDirectory)  # Save the tokenizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvm-jP0i4Gig"
      },
      "source": [
        "#### Reload the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXHXb7RYTARC"
      },
      "outputs": [],
      "source": [
        "# Reload the saved model and tokenizer.\n",
        "model = taskType.from_pretrained(modelDirectory, num_labels=len(targets)).to(\"cuda\")\n",
        "tokenizer = tokenizerType.from_pretrained(modelDirectory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96uWKthsR8fS"
      },
      "outputs": [],
      "source": [
        "def predict(*args):\n",
        "    \"\"\"\n",
        "    Takes as input a string, text, then predicts if\n",
        "    text is sarcastic (1) or not sarcastic (0).\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenize the text, then run the input\n",
        "    # through the model and take the argmax\n",
        "    # to get a probability.\n",
        "    inputs = tokenizer(*args, padding=True, truncation=True,\n",
        "                       max_length=maxLength, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model(**inputs)\n",
        "    probs = outputs[0].softmax(1)\n",
        "\n",
        "    # Return whether the text is sarcastic (1)\n",
        "    # or not sarcastic (0).\n",
        "    return probs.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUaasmhpSYcg"
      },
      "outputs": [],
      "source": [
        "accuracy = 0  # A value to hold the number of correctly predicted comments.\n",
        "\n",
        "# Loop for all the data in the test set\n",
        "# and compute the accuracy for the test set.\n",
        "for value in zip(testData[0], *testData[1:]):\n",
        "    accuracy += (predict(*value[1:]) == value[0])\n",
        "\n",
        "print(f\"The testing accuracy is {accuracy} / \"\n",
        "      f\"{len(testData[0])} = {accuracy / len(testData[0])}.\")\n",
        "print(f\"There are {sum(testData[0])} sarcastic samples in the test set.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}